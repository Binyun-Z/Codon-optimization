{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import collections\n",
    "from random import randint\n",
    "from Bio.SeqUtils import GC\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "\n",
    "# ------------------------ Variable definition (codon table) --------------------------- #\n",
    "\n",
    "# Assign full codon table on which to operate codon selection based on user's input\n",
    "# 分配完整的密码子表，根据用户输入操作密码子选择\n",
    "codon_table_full = { 'A': ['GCT','GCC','GCA','GCG'],\n",
    "                'C': ['TGT','TGC'],\n",
    "                'D': ['GAT','GAC'],\n",
    "                'E': ['GAA','GAG'],\n",
    "                'F': ['TTT','TTC'],\n",
    "                'G': ['GGT','GGC','GGA','GGG'],\n",
    "                'H': ['CAT','CAC'],\n",
    "                'I': ['ATT','ATC','ATA'],\n",
    "                'K': ['AAA','AAG'],\n",
    "                'L': ['TTA','TTG','CTT','CTC','CTA','CTG'],\n",
    "                'M': ['ATG'],\n",
    "                'N': ['AAT','AAC'],\n",
    "                'P': ['CCT','CCC','CCA','CCG'],\n",
    "                'Q': ['CAA','CAG'],\n",
    "                'R': ['CGT','CGC','CGA','CGG','AGA','AGG'],\n",
    "                'S': ['AGT','AGC','TCT','TCC','TCA','TCG'],\n",
    "                'T': ['ACT','ACC','ACA','ACG'],\n",
    "                'V': ['GTT','GTC','GTA','GTG'],\n",
    "                'W': ['TGG'],\n",
    "                'Y': ['TAT','TAC'],\n",
    "                '*': ['TAG','TAA','TGA'] }  \n",
    "\n",
    "\n",
    "class DG:\n",
    "    def __init__(self, cfg = None,codon_table_full = codon_table_full):\n",
    "        self.my_prot = cfg.seqs #m目的蛋白\n",
    "        self.seqVars =cfg.seqVars # 生成的不同基因数量\n",
    "        self.host = cfg.host   # 表达宿主\n",
    "        self.rar_thr=cfg.rar_thr #输入 RSCU 值，低于该值的密码子将被丢弃\n",
    "        self.gc_thr = cfg.gc_thr #输入 RSCU 值，低于该值不以 G/C 结尾的密码子将被丢弃：\n",
    "        self.codon_table_full = codon_table_full\n",
    "        self.host_path = self.host+'_release.csv'\n",
    "        self.codon_table = self.generate_codon_table()\n",
    "    def generate_codon_table(self):\n",
    "            rscu = pd.read_csv(self.host_path)\n",
    "    \n",
    "            # Extract amino acid symbols (one-letter code) from .csv file\n",
    "            symb = rscu['AmOneLet']\n",
    "            # Initialise a dictionary with unique amino acid symbols as keys\n",
    "            codon_table = {}\n",
    "            for s in symb:\n",
    "                if s not in codon_table:\n",
    "                    codon_table[s] = []\n",
    "                    \n",
    "            # Extract parameters from .csv file\n",
    "            cod = rscu['Codon']\n",
    "            val = rscu['RSCU']\n",
    "            gc3 = rscu['GC3']\n",
    "            \n",
    "            # Fill codon table with codons above thresholds\n",
    "            for index in range(len(symb)):\n",
    "                # Only consider codons if above 'rare threshold'\n",
    "                if val[index] > self.rar_thr:\n",
    "                    # If above threshold, take all cods with rscu above gc_thr or ones ending in g/c (regardless of val) \n",
    "                    if val[index] > self.gc_thr or gc3[index] == 'Y':\n",
    "                        codon_table[symb[index]].append(cod[index])\n",
    "                        \n",
    "                                \n",
    "            # If RSCU thresholds set too high, most highly expressed codons are added to codon_table\n",
    "            \n",
    "            # Create a tuple with (symb, cod, val), used below to take most highly expressed codon\n",
    "            bund = [ (symb[i], cod[i], val[i]) for i in range(len(cod)) ]\n",
    "            \n",
    "            # Cycle through keys (amino acids) in codon_table\n",
    "            for key in codon_table:\n",
    "                # If amino acids without corresponding codons are found..\n",
    "                if codon_table[key] == []:\n",
    "                    if key != 'W' and key != 'M':\n",
    "                        print('Using only most highly expressed codon for amino acid %s' % key)\n",
    "                    # Add most highly expressed codon from codon usage table\n",
    "                    pool = [ bund[x] for x in range(len(bund)) if bund[x][0] == key ]\n",
    "                    c = max(pool, key=lambda item:item[2])[1]\n",
    "                    codon_table[key].append(c)\n",
    "                    \n",
    "            return codon_table\n",
    "    def RSCU(self,path):\n",
    "        \"\"\"Given a path (argv) to codon usage table of expression host, functions generates a dictionary\n",
    "        with all RSCU values (return).\"\"\"\n",
    "        \n",
    "        # Read codon_usage table from data folder\n",
    "        codon_usage = pd.read_csv(path)\n",
    "        \n",
    "        # Initialise dictionary where RSCU values will be stored {triplet:RSCU val}\n",
    "        RSCU_dict = {}\n",
    "        \n",
    "        # Cycle through codon_usage, extract info and load onto dictionary\n",
    "        for i in range(len(codon_usage['Codon'])):\n",
    "            RSCU_dict[codon_usage['Codon'][i]] = codon_usage['RSCU'][i]\n",
    "            \n",
    "        return  RSCU_dict\n",
    "    def relative_adaptiveness(self,codon_table_full, path):\n",
    "        \"\"\"Calculates the relative adaptiveness of each codon given a path to a codon usage table.\"\"\"\n",
    "        \n",
    "        # Define RSCU_dict using RSCU function\n",
    "        RSCU_dict = self.RSCU(path)\n",
    "        \n",
    "        # For each amino acid, compute the max(RSCU) of synonymous codons\n",
    "        # Initialise a dictionary, keys are cods, vals max RSCU\n",
    "        maxRSCU_dict = {}\n",
    "        for aa in codon_table_full:\n",
    "            RSCUvals = [ RSCU_dict[cod] for cod in codon_table_full[aa] ]\n",
    "            for cod in codon_table_full[aa]:\n",
    "                maxRSCU_dict[cod] = max(RSCUvals)\n",
    "        \n",
    "        # Now define a relative adaptiveness dict, keys are cods, vals are ratios RSCU_cod/RSCU_max\n",
    "        relative_adaptiveness_dict = {}\n",
    "        for cod in RSCU_dict:\n",
    "            relative_adaptiveness_dict[cod] = RSCU_dict[cod]/maxRSCU_dict[cod]\n",
    "            \n",
    "        return relative_adaptiveness_dict\n",
    "    def CAI_calculator(self,codon_table_full, path, seq):\n",
    "\n",
    "        # Generate relative_adaptiveness dictionary\n",
    "        relative_adaptiveness_dict = self.relative_adaptiveness(codon_table_full, path)\n",
    "\n",
    "        if len(seq) % 3 != 0:\n",
    "            raise ValueError('length of sequence is not a multiple of three')\n",
    "        \n",
    "        # Initialise a list where codon adaptiveness values will be stored     \n",
    "        seq_adaptiveness = []\n",
    "\n",
    "        # Traverse coding sequence and extract codons\n",
    "        for i in range(0,len(seq),3):\n",
    "            cod = seq[i:i+3]\n",
    "            cod_adaptiveness = relative_adaptiveness_dict[cod]\n",
    "            seq_adaptiveness.append(cod_adaptiveness)\n",
    "        \n",
    "        # Calculate the geometric mean for the list seq_adaptiveness (= CAI)\n",
    "        CAI = scipy.stats.mstats.gmean(seq_adaptiveness)\n",
    "        \n",
    "        return CAI\n",
    "    def find_identities(self,l):\n",
    "        \"\"\"\n",
    "        Takes in a list and returns a dictionary with seqs as keys and positions of identical elements in list as values.\n",
    "        argvs: l =  list, e.g. mat[:,x]\n",
    "        \"\"\"\n",
    "\n",
    "        # the number of items in the list will be the number of unique types\n",
    "        uniq = [item for item, count in collections.Counter(l).items()]\n",
    "        \n",
    "        # Initialise a dictionary that will hold the results\n",
    "        identDict = {}\n",
    "        for item in uniq:\n",
    "            identDict[item] = [ x for x in range(len(l)) if l[x] == item ]\n",
    "            \n",
    "        return identDict \n",
    "    \n",
    "    def alternate(self):\n",
    "        \"\"\"A function that produces a generator\n",
    "        Usage: alternator = alternate() \"\"\" \n",
    "\n",
    "        while True:\n",
    "            yield 0\n",
    "            yield 1\n",
    "    def lib_generator(self):\n",
    "        \"\"\"\n",
    "        Function to generate set of diversified coding sequences. \n",
    "        生成一组多样化编码序列的函数。\n",
    "        argvs: my_prot = amino acid sequence of the protein in question (string),\n",
    "        seqVars = number of coding sequence to generate (integer),\n",
    "        codon_table: codon usage table for the specified expression host (dict)\n",
    "        \"\"\"\n",
    "        my_prot, seqVars, codon_table = self.my_prot,self.seqVars*2,self.codon_table\n",
    "        ### --- Preliminary operations, e.g. variables' initiation\n",
    "        # N is the number of codons, same as the number of aa's in our protein sequence\n",
    "        # N 是密码子的数量，与我们蛋白质序列中 aa 的数量相同\n",
    "        N = len(my_prot)\n",
    "        \n",
    "        # Initialise data structure to store CDS variants\n",
    "        # 初始化数据结构以存储 CDS 变体\n",
    "        # use np array with dtype = string of 3 chars, as each codon is stored separately\n",
    "        # 使用 dtype = string of 3 chars 的 np array，因为每个密码子都是单独存储的\n",
    "        mat = np.zeros((seqVars,N), dtype='S3') #s3表示长度为3的字符串\n",
    "        \n",
    "        # create a list (codVars) with all codon variants at each position\n",
    "        codVars = []\n",
    "        # Fill codVars with a loop\n",
    "        for aa in my_prot:\n",
    "            codVars.append(codon_table[aa])\n",
    "            \n",
    "        # Check that dimensions of codVars and recipient data structure mat are compatible\n",
    "        if len(codVars) != mat.shape[1]:\n",
    "            raise ValueError('list of codon vars and matrix incompatible')   \n",
    "            \n",
    "        ### --- 现在填充mat的前两个位置\n",
    "        \n",
    "        # Pos 1, where we ensure that ATG is the starting codon\n",
    "        # Pos 1，我们确保 ATG 是起始密码子\n",
    "        if codVars[0] != ['ATG']:\n",
    "            raise ValueError('first codon is not ATG')\n",
    "        mat[:,0] = codVars[0]\n",
    "\n",
    "        # Pos 2, where we ensure available codon variants are spread across growing sequences\n",
    "        # Pos 2，我们确保可用的密码子变体分布在不断增长的序列中\n",
    "        cur = 0\n",
    "        while cur < seqVars:\n",
    "            # Trick to cycle through codon variants and assign them to mat\n",
    "            # 循环密码子变体并将它们分配给mat\n",
    "            codIndex = cur - (cur//len(codVars[1]))*len(codVars[1])\n",
    "            mat[cur,1] = codVars[1][codIndex]\n",
    "            cur += 1  \n",
    "            \n",
    "        ### --- Method for comparing sequences and sort them into different sets\n",
    "        \n",
    "        # cycle through codVars (= codon variants, list of lists) and fill mat \n",
    "        for k in range(2,len(codVars) ):\n",
    "            \n",
    "            # Initialise final and initial positions for joining codons\n",
    "            # iniPos will change within the while loop\n",
    "            finPos = k \n",
    "            iniPos = k - 1\n",
    "            \n",
    "            # Initialise data frame to hold identity dictionaries, could be a list of dicts\n",
    "            idents = []\n",
    "            \n",
    "            \n",
    "            #### From here we have an iterative logic block, whereby\n",
    "            #### 1) identities of stretches with increasing length are evaluated;\n",
    "            #### 2) for each position to fill (k), a list of dictionaries is returned\n",
    "            \n",
    "            # Create a switch to exit while loop when appropriate\n",
    "            switch = 1\n",
    "            \n",
    "            while switch == 1:\n",
    "            \n",
    "                # Initialise joint Codons list\n",
    "                jointCods = []\n",
    "                \n",
    "                # Create the set that will be submitted to find_identities() function\n",
    "                for x in range(seqVars):\n",
    "                    jointCods.append(\"\".join([mat[x,p].decode() for p in range(iniPos,finPos)]))   \n",
    "                    \n",
    "                # Deploy find_identities() on jointCods\n",
    "                identDict = self.find_identities(jointCods)         \n",
    "                \n",
    "                ## Add hypothetical case where there are no identities at all\n",
    "                \n",
    "                # Clause to break out of while loop: if there are no identities or if first\n",
    "                # codon has been reached \n",
    "                \n",
    "                ### Note: we do not want the last entry in idents to be singlets\n",
    "                ### UNLESS, iniPos = k - 1, i.e. there no terminal identities\n",
    "                \n",
    "                if iniPos == k - 1 and max([len(x) for x in identDict.values()]) == 1:\n",
    "                    ### We are allowed to have singlets and return\n",
    "                    idents.append(identDict)\n",
    "                    ### Exit while loop by turning switch off\n",
    "                    switch = 0\n",
    "                    \n",
    "                ### We do not want to append the last comparison with singlets, so we do\n",
    "                ### not append with the following condition, just turn off the switch    \n",
    "                if max([len(x) for x in identDict.values()]) == 1 or iniPos == 0:\n",
    "                    \n",
    "                    ### Exit while loop by turning switch off\n",
    "                    switch = 0\n",
    "                    \n",
    "                elif max([len(x) for x in identDict.values()]) > 1:\n",
    "                    ### Add ident dict to idents\n",
    "                    idents.append(identDict)\n",
    "                    ### Do not turn switch off but move iniPos back instead\n",
    "                    iniPos = iniPos - 1\n",
    "                    \n",
    "                else:\n",
    "                    raise ValueError('problem with identDict evaluation or logic')\n",
    "            \n",
    "            \n",
    "            ########### ----------------- Block 1 ends here ----------------------############\n",
    "            \n",
    "            # Case where only one codon is available: just fill all seqs with that\n",
    "            if len(codVars[k]) == 1:\n",
    "                cod = codVars[k][0] \n",
    "                for pos in range(seqVars):\n",
    "                    mat[pos,k] = cod\n",
    "                    \n",
    "            else:\n",
    "                ########### ----------------- Block 2 ----------------- ######################\n",
    "                \n",
    "                # Start with special condition, note list around list\n",
    "                if len(idents) == 1:\n",
    "                    outerDict_temp = {}\n",
    "                    for key in idents[0]:\n",
    "                        outerDict_temp[key] = [ idents[0][key] ]\n",
    "                    \n",
    "                if len(idents) > 1:\n",
    "                    # Extract outer idents layer in dictionary\n",
    "                    outerDict = idents[0]\n",
    "                    outerDict_temp = {}\n",
    "                    # Create a second dictionary with same keys as above, but empty value-lists\n",
    "                    for item in outerDict:\n",
    "                        outerDict_temp[item] = [] \n",
    "                        \n",
    "                    # Sequence clustering\n",
    "                    \n",
    "                    # Cycle through all layers in idents (including 3-bp homology layer, i.e. outermost layer)\n",
    "                    for cur in range(1, len(idents) + 1):\n",
    "                        # print 'cur is:', cur\n",
    "                        index = -cur\n",
    "                        # Take sequences for which there are > 1 ID's\n",
    "                        \n",
    "                        longestHom = [ x for x in idents[index] if len(idents[index][x]) > 1 ]\n",
    "                        # Cycle through items in longestHom   \n",
    "                        for item in longestHom:\n",
    "                    \n",
    "                            # Define last triplet as key for outerDict_temp (storage Dict)\n",
    "                            currentKey = item[-3:]\n",
    "                        \n",
    "                            # Define elements corresponding to item in longestHom\n",
    "                            l = [ x for x in idents[index][item] ]\n",
    "                        \n",
    "                            # if outerDict_temp[currentKey] is empty, just append\n",
    "                            if outerDict_temp[currentKey] == []:\n",
    "                                outerDict_temp[currentKey].append(l)\n",
    "                                \n",
    "                            else:\n",
    "                                \n",
    "                        \n",
    "                                # Two cases - 1) no item in l is present in outerDict_temp[currentKey]\n",
    "                            \n",
    "                                # all items in outerDict_temp[currentKey] as a set\n",
    "                                all_items = set( x for sublist in outerDict_temp[currentKey] for x in sublist )\n",
    "                            \n",
    "                                # if l and all_items do not share elements\n",
    "                                if set(l).isdisjoint(all_items):\n",
    "                            \n",
    "                                    # Append list l to outerDict_temp\n",
    "                                    outerDict_temp[currentKey].append(l)\n",
    "                            \n",
    "                                # 2) they are not disjoint\n",
    "                                else:\n",
    "                                    \n",
    "                                    # Cycle through sublists in dict\n",
    "                                    for sublist in outerDict_temp[currentKey]:\n",
    "                                        \n",
    "                                        # if a sublist shares items with l\n",
    "                                        if not set(l).isdisjoint(set(sublist)):\n",
    "                                    \n",
    "                                            # Find items NOT in common\n",
    "                                            dif = set(l).difference(set(sublist))\n",
    "                                        \n",
    "                                            # Cycle through them\n",
    "                                            for e in dif:\n",
    "                                        \n",
    "                                                # If e is not already in all_items\n",
    "                                                if e not in all_items:\n",
    "                                                \n",
    "                                                    # Append element to sublist and update all_items\n",
    "                                                    sublist.append(e)\n",
    "                                                    all_items.add(e)\n",
    "                                                    \n",
    "                ## Special condition - if singlets are present throughout the depth of idents,\n",
    "                ## these are not considered. Fix by collecting them at the end\n",
    "                for key in outerDict_temp:\n",
    "                    if outerDict_temp[key] == []:\n",
    "                        # print 'FIXING BUG'\n",
    "                        outerDict_temp[key] = [idents[0][key]]\n",
    "                                        \n",
    "                ####################### -------------------------- ###########################                \n",
    "                    \n",
    "                ########### Module 3 -  filling module ###################\n",
    "                ### Now we work on outerDict_temp\n",
    "                \n",
    "                # Initialise generator/alternator\n",
    "                #print 'alternator is being initialised'\n",
    "                alternator = self.alternate() \n",
    "                #print 'alternator is on: ', alternator\n",
    "                \n",
    "            \n",
    "                codList = [ x for x in codVars[k] ]    \n",
    "                \n",
    "                # Shuffle codList\n",
    "                random.shuffle(codList)\n",
    "\n",
    "                # Split the shuffled list into two\n",
    "                x1 = codList[0:len(codList)//2]\n",
    "                x2 = codList[len(codList)//2:len(codList)]\n",
    "                # Then we put them together\n",
    "                pool = [x1, x2]\n",
    "            \n",
    "                # Initialise state, only done on first iteration\n",
    "                if k == 2:\n",
    "                    state = alternator.__next__()\n",
    "                    \n",
    "                # Before starting work on this 'k', ensure state is on 0\n",
    "                if state == 1:\n",
    "                    state = alternator.__next__()\n",
    "                \n",
    "                # Cycle through items in dictionary, each set defined as workingList\n",
    "                for item in outerDict_temp:\n",
    "                    workingList = outerDict_temp[item]     ###### SET OF LISTS\n",
    "                \n",
    "                    # Cycle through sublists in workingList\n",
    "                    for sub in workingList:\n",
    "                        # On making this transition, we re-define x1 and x2\n",
    "                    \n",
    "                        for id in sub:                     ###### SINGLE ID      \n",
    "                    \n",
    "                            ### Within the same sub list, we can flick between x1 and x2 when they are used up\n",
    "                            \n",
    "                            if pool[state] == []:\n",
    "                                ### Switch to codon sublist not in use\n",
    "                                state = alternator.__next__()\n",
    "                            \n",
    "                                ### Reload previous state\n",
    "                                pool[state - 1] = [ x for x in codVars[k] if x not in pool[state] ]\n",
    "                                \n",
    "                            ## Standard lines for choosing codon and appending to matrix\n",
    "                            if pool[state] == []:\n",
    "                                state = alternator.__next__()\n",
    "                            cod = random.choice(pool[state])\n",
    "                            mat[id,k] = cod\n",
    "                        \n",
    "                            pool[state].remove(cod)\n",
    "                            \n",
    "                        ## Here we re-define x1 and x2, based on state\n",
    "                        ######### Note: now adopting a new strategy, previous cod in unitTest if nec.\n",
    "                        if state == 0:\n",
    "                            # x2 becomes = leftovers of x1 + x2, and state switches\n",
    "                            x2 = pool[state] + pool[state - 1]\n",
    "                            x1 = [ x for x in codVars[k] if x not in x2]\n",
    "                            pool = [x1,x2]\n",
    "                            # Now we switch the state\n",
    "                            state = alternator.__next__()\n",
    "                            # \n",
    "                        if state == 1:\n",
    "                            # x2 is leftovers of x2, state remains the same\n",
    "                            x2 = pool[state]\n",
    "                            x1 = [ x for x in codVars[k] if x not in x2]\n",
    "                            pool = [x1,x2]\n",
    "                            #### note: remaining in state 1\n",
    "            \n",
    "                            \n",
    "            # Alternator must be initialised \"manually\" in the special case where there is only one\n",
    "            # codon option at k = 2.              \n",
    "            if k == 2 and len(codVars[k]) == 1:\n",
    "                alternator = self.alternate()\n",
    "                state = alternator.__next__()\n",
    "                \n",
    "                    \n",
    "\n",
    "        # Convert matrix mat to list of sequences\n",
    "        mySeqs = []\n",
    "        for ind in range(seqVars):\n",
    "            s = ''\n",
    "            for cod in mat[ind,:]:\n",
    "                s = s + cod.decode()\n",
    "            mySeqs.append(s)   \n",
    "                \n",
    "        return mySeqs\n",
    "    def hamming_distance(self,s1,s2):\n",
    "        \"\"\" Takes two strings as input and\n",
    "        returns the number of mismatches as type integer\"\"\"\n",
    "        if len(s1) != len(s2):\n",
    "            raise ValueError(\"Undefined for sequences of unequal length\")\n",
    "        return sum(ch1 != ch2 for ch1, ch2 in zip(s1, s2))\n",
    "    \n",
    "    def hamming_matrix(self,pool):\n",
    "        \"\"\"Takes in a list of sequences (pool) and returns \n",
    "        a matrix with pairwise hamming distances\"\"\"\n",
    "        \n",
    "        # Make sure pool variable is a list\n",
    "        if type(pool) != list:\n",
    "            raise ValueError('Pool is not a list')\n",
    "        \n",
    "        # Array dimension\n",
    "        dimLen = len(pool)\n",
    "        \n",
    "        # Generate array of zeros\n",
    "        hammingMatrix = np.zeros((dimLen,dimLen))\n",
    "        \n",
    "        # Fill hammingMatrix with hamming distances - symmetrical matrix\n",
    "        for i,ele_1 in enumerate(pool):\n",
    "        \n",
    "            for j,ele_2 in enumerate(pool):\n",
    "            \n",
    "                # Only fill in upper triangle\n",
    "                if j >= i:\n",
    "                    break\n",
    "                # Calculate distance\n",
    "                misMatches = self.hamming_distance(ele_1,ele_2)\n",
    "                # Fill in array\n",
    "                hammingMatrix[i,j] = misMatches\n",
    "                # Same for symmetrical element\n",
    "                hammingMatrix[j,i] = misMatches\n",
    "                \n",
    "        return hammingMatrix\n",
    "    def hamming_stats(self,pool):\n",
    "        \"\"\"Generates a hammingMatrix with hamming_matrix()\n",
    "        and calculates mean distance, minimum and maximum \n",
    "        divergence (in %)\"\"\"\n",
    "        \"\"\"Generates a hammingMatrix with hamming_matrix()\n",
    "        and calculates mean distance, minimum and maximum \n",
    "        divergence (in %)\"\"\"\n",
    "        \n",
    "        # Generate array with hamming distances\n",
    "        divArray = self.hamming_matrix(pool)\n",
    "        # Store len of divArray\n",
    "        dimA = divArray.shape[0]\n",
    "        \n",
    "        # Extract upper triangular elements\n",
    "        iu = np.triu_indices(dimA)\n",
    "        upTri = [ ele for ele in divArray[iu] if ele != 0 ] # excludes diagonal values\n",
    "        \n",
    "        # Calculate mean of upTri and express it in percentage\n",
    "        meanHam = np.mean(upTri)\n",
    "        \n",
    "        # Express mean in percentage - meanHam/len(sequence)\n",
    "        meanHamPer = float( meanHam/(len(pool[0]))) * 100.0\n",
    "        \n",
    "        # Extract the smallest hamming distance\n",
    "        minHam = np.min(upTri)\n",
    "        \n",
    "        # Express min in percentage\n",
    "        minHamPer = float( minHam/(len(pool[0]))) * 100.0\n",
    "        \n",
    "        maxHam = np.max(upTri)\n",
    "        \n",
    "        # Express max in percentage - meanHam/len(sequence)\n",
    "        maxHamPer = float( maxHam/(len(pool[0]))) * 100.0\n",
    "        # 这段代码定义了一个名为 hamming_stats 的函数，用于生成 Hamming 矩阵并计算平均距离、最小和最大偏离值（以百分比表示）。\n",
    "\n",
    "        # 具体分析如下：\n",
    "\n",
    "        # 函数接受一个参数 pool，作为输入数据。\n",
    "\n",
    "        # hamming_matrix 函数被调用，传入 pool 参数，用于生成一个 Hamming 矩阵。Hamming 矩阵的生成过程在这段代码中未展示，可能位于函数 hamming_matrix 的内部或者其他地方。\n",
    "\n",
    "        # 生成的 Hamming 矩阵被存储在变量 divArray 中。\n",
    "\n",
    "        # 使用 divArray 的维度信息，获取上三角部分的元素。通过 np.triu_indices(dimA) 获取上三角部分的索引，然后使用这些索引从 divArray 中提取对应的元素。这些元素构成了列表 upTri，排除了对角线上的值。\n",
    "\n",
    "        # 计算 upTri 列表中元素的平均值，存储在变量 meanHam 中。\n",
    "\n",
    "        # 将 meanHam 的值除以输入数据中的序列长度，并乘以 100，将平均值转换为百分比形式，存储在变量 meanHamPer 中。\n",
    "\n",
    "        # 从 upTri 列表中找到最小的距离值，存储在变量 minHam 中。\n",
    "\n",
    "        # 将 minHam 的值除以输入数据中的序列长度，并乘以 100，将最小值转换为百分比形式，存储在变量 minHamPer 中。\n",
    "\n",
    "        # 从 upTri 列表中找到最大的距离值，存储在变量 maxHam 中。\n",
    "\n",
    "        # 将 maxHam 的值除以输入数据中的序列长度，并乘以 100，将最大值转换为百分比形式，存储在变量 maxHamPer 中。\n",
    "\n",
    "        # 总结来说，这段代码使用输入数据生成 Hamming 矩阵，并计算了平均距离、最小和最大偏离值（以百分比表示）。这些计算结果分别存储在 meanHamPer、minHamPer 和 maxHamPer 这三个变量中。需要注意的是，这段代码使用了 numpy 库中的函数和数据结构来进行矩阵操作和计算。\n",
    "\n",
    "        return (meanHamPer,minHamPer,maxHamPer)\n",
    "    def longest_cont(self,s1,s2):\n",
    "        \"\"\"Works out the longest stretch of identical bases between two\n",
    "        degenerate coding sequences\"\"\"\n",
    "        if len(s1) != len(s2):\n",
    "            raise ValueError(\"Undefined for sequences of unequal length\")\n",
    "        res = ''\n",
    "        for ch1, ch2 in zip(s1,s2):\n",
    "            if ch1 == ch2:\n",
    "                res += '1'\n",
    "            else:\n",
    "                res += '0'        \n",
    "        #print res   ### Need to subdivide into chunks of contiguous 1's (and 0's)\n",
    "                \n",
    "        return np.max([len(x) for x in re.compile(\"(1+1)*\").findall(res)])\n",
    "    def longest_cont_matrix(self,pool):\n",
    "\n",
    "        \"\"\"Takes in a list of sequences (pool) and returns \n",
    "        a matrix with longest stretch of identity\"\"\"\n",
    "        \n",
    "        # Make sure pool variable is a list\n",
    "        if type(pool) != list:\n",
    "            raise ValueError('Pool is not a list')\n",
    "        \n",
    "        # Array dimension\n",
    "        dimLen = len(pool)\n",
    "        \n",
    "        # Generate array of zeros\n",
    "        longestMatrix = np.zeros((dimLen,dimLen))\n",
    "        \n",
    "        # Fill longestMatrix with identity values - symmetrical matrix\n",
    "        for i,ele_1 in enumerate(pool):\n",
    "        \n",
    "            for j,ele_2 in enumerate(pool):\n",
    "            \n",
    "                # Only fill in upper triangle\n",
    "                if j >= i:\n",
    "                    break\n",
    "                # Calculate distance\n",
    "                idents = self.longest_cont(ele_1,ele_2)\n",
    "                # Fill in array\n",
    "                longestMatrix[i,j] = idents\n",
    "                # Same for symmetrical element\n",
    "                longestMatrix[j,i] = idents\n",
    "                \n",
    "        return longestMatrix\n",
    "    def abs_longest(self,pool):\n",
    "        \"\"\"takes in a list of sequences (pool) and returns the longest stretch of homology\n",
    "        that can be found in the set\"\"\"\n",
    "        \n",
    "        # Call longest_cont_matrix() and take the upper triangular region\n",
    "        mat = np.triu(self.longest_cont_matrix(pool))\n",
    "        store_seq = []\n",
    "        # dump non-zero elements into store_seq\n",
    "        for row in mat:\n",
    "            for ele in row:\n",
    "                if ele != 0:\n",
    "                    store_seq.append(ele)\n",
    "        # return max\n",
    "        return (np.min(store_seq),np.max(store_seq)) \n",
    "    def delete_abs_longest(self,pool,idx):\n",
    "        \"\"\"takes in a list of sequences (pool) and returns the longest stretch of homology\n",
    "        that can be found in the set\"\"\"\n",
    "        \n",
    "        # Call longest_cont_matrix() and take the upper triangular region\n",
    "        mat = np.triu(self.longest_cont_matrix(pool))\n",
    "        store_seq = []\n",
    "        # dump non-zero elements into store_seq\n",
    "        for i in range(mat.shape[0]):\n",
    "            if i==idx:\n",
    "                continue\n",
    "            for j in range(mat.shape[1]):\n",
    "                if i==idx:\n",
    "                    continue\n",
    "                ele = mat[i][j]\n",
    "                if ele != 0:\n",
    "                    store_seq.append(ele)\n",
    "        # return max\n",
    "        \n",
    "        return (np.min(store_seq),np.max(store_seq)) \n",
    "    # --------------------------- Main functions' definitions: END ------------------------- #\n",
    "    def delete_seq(self,mySeqs,n):\n",
    "        to_delete = []\n",
    "        homology = self.abs_longest(mySeqs)\n",
    "        # hamper = self.hamming_stats(mySeqs)\n",
    "        minhomology=homology[0]\n",
    "        maxhomology=homology[1]\n",
    "        \n",
    "        # meanHamPer=HamPer[0]\n",
    "        # minHamPer=HamPer[1]\n",
    "        # maxHamPer=HamPer[2]\n",
    "        for i in range(n):\n",
    "            sequence_to_delete = -1\n",
    "            for seq_idx in range(len(mySeqs)):\n",
    "                homology_tmp = self.delete_abs_longest(mySeqs,seq_idx)[1]\n",
    "\n",
    "                if homology_tmp<maxhomology:\n",
    "\n",
    "                    maxhomology = homology_tmp\n",
    "                    sequence_to_delete = seq_idx\n",
    "                print(sequence_to_delete)\n",
    "            \n",
    "            to_delete.append(sequence_to_delete)\n",
    "\n",
    "        print('============================>>>>>>>>>>')\n",
    "        print(to_delete)\n",
    "\n",
    "        for di in to_delete:\n",
    "            del mySeqs[di]\n",
    "        # if(len(mySeqs)>self.seqVars):\n",
    "        #     mySeqs = mySeqs[0:self.seqVars]\n",
    "\n",
    "        return(mySeqs)\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        mySeqs = self.lib_generator()\n",
    "        mySeqs = self.delete_seq(mySeqs,n = self.seqVars)\n",
    "\n",
    "        IDlist = [ 'seq' + str(i) for i in range(len(mySeqs)) ]\n",
    "\n",
    "        CAIlist = []\n",
    "        for seq in mySeqs:\n",
    "            CAIlist.append(self.CAI_calculator(codon_table_full = self.codon_table_full, path = self.host_path, seq = seq))\n",
    "\n",
    "        GClist = []\n",
    "        for seq in mySeqs:\n",
    "            GClist.append(GC(seq))\n",
    "\n",
    "        output_data = {'seq ID': IDlist, 'Sequence': mySeqs, 'CAI': CAIlist, 'GC %': GClist}\n",
    "        df = pd.DataFrame(output_data)\n",
    "        print( df )\n",
    "\n",
    "        print( 'Stats: Mean, minimum and maximum hamming distances in the sequence set are (per cent):', self.hamming_stats(mySeqs))\n",
    "        print ('Stats: Longest stretch of homology between any two sequences (in bp):', self.abs_longest(mySeqs))\n",
    "        # \n",
    "        df.to_csv('codingSequenceVariants.csv', sep = ',')\n",
    "        return(self.hamming_matrix(mySeqs),self.hamming_stats(mySeqs),self.longest_cont_matrix(mySeqs),self.abs_longest(mySeqs))\n",
    "\n",
    "class Parameter:\n",
    "    def __init__(self,my_prot = './500bp.fasta' ,seqVars = 10,host = 'CLIB',description='用户自定义参数',\n",
    "                 rar_thr = 0.5,gc_thr = 0.8):\n",
    "        self.my_prot = my_prot\n",
    "        self.seqVars =seqVars # 生成的不同基因数量\n",
    "        self.host = host   # 表达宿主\n",
    "        # self.host_path = self.host+'_codon_usage.csv' #同义密码子使用说明\n",
    "        self.rar_thr=rar_thr #输入 RSCU 值，低于该值的密码子将被丢弃\n",
    "        self.gc_thr = gc_thr #输入 RSCU 值，低于该值不以 G/C 结尾的密码子将被丢弃：\n",
    "        self.description = description\n",
    "        self.seqs = self.get_seq()\n",
    "    def get_seq(self):\n",
    "        seqlist = []\n",
    "        for seqercord in SeqIO.parse(self.my_prot,\"fasta\"):\n",
    "            seqlist.append(str(seqercord.seq))\n",
    "        return(seqlist[0])\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.name}={self.value}'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqVars_list = [10]\n",
    "# seqVars_list = seqVars_list+[int((i+1)*50) for i in range(10)]\n",
    "# seqVars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "============================>>>>>>>>>>\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "  seq ID                                           Sequence       CAI  \\\n",
      "0   seq0  ATGGTTTTTACTACCGAGGACTTTGTGGGTGACTGGCGCCAGACTG...  0.817900   \n",
      "1   seq1  ATGGTCTTCACCACGGAGGACTTCGTTGGAGACTGGCGGCAGACGG...  0.821496   \n",
      "2   seq2  ATGGTGTTCACGACGGAGGACTTCGTCGGCGACTGGAGACAGACCG...  0.839633   \n",
      "3   seq3  ATGGTTTTCACGACTGAGGACTTCGTCGGAGACTGGCGACAGACGG...  0.817647   \n",
      "4   seq4  ATGGTCTTTACCACGGAGGACTTTGTTGGCGACTGGAGACAGACGG...  0.825551   \n",
      "5   seq5  ATGGTGTTTACGACGGAGGACTTTGTCGGAGACTGGCGGCAGACCG...  0.824648   \n",
      "6   seq6  ATGGTTTTTACCACTGAGGACTTCGTTGGCGACTGGCGCCAGACCG...  0.833452   \n",
      "7   seq7  ATGGTCTTCACGACCGAGGACTTCGTTGGTGACTGGCGCCAGACCG...  0.832976   \n",
      "8   seq8  ATGGTGTTTACCACCGAGGACTTCGTGGGAGACTGGAGACAGACGG...  0.863627   \n",
      "9   seq9  ATGGTTTTCACTACGGAGGACTTTGTGGGAGACTGGCGACAGACCG...  0.802238   \n",
      "\n",
      "        GC %  \n",
      "0  51.267057  \n",
      "1  53.996101  \n",
      "2  55.360624  \n",
      "3  52.631579  \n",
      "4  54.191033  \n",
      "5  53.801170  \n",
      "6  54.191033  \n",
      "7  53.996101  \n",
      "8  53.411306  \n",
      "9  51.656920  \n",
      "Stats: Mean, minimum and maximum hamming distances in the sequence set are (per cent): (15.798137318605157, 13.840155945419102, 19.103313840155945)\n",
      "Stats: Longest stretch of homology between any two sequences (in bp): (14.0, 29.0)\n"
     ]
    }
   ],
   "source": [
    "minhomology_list = []\n",
    "maxhomology_list = []\n",
    "meanHamPer_list = []\n",
    "minHamPer_list = []\n",
    "maxHamPer_list = []\n",
    "num_seq = 10\n",
    "for seqVars in seqVars_list:\n",
    "    cfg = Parameter(seqVars = seqVars)\n",
    "    instance = DG(cfg,codon_table_full)\n",
    "    hamming_matrix,HamPer,longest_cont_matrix,homology = instance.run()\n",
    "    minhomology_list.append(homology[0])\n",
    "    maxhomology_list.append(homology[1])\n",
    "    \n",
    "    meanHamPer_list.append(HamPer[0])\n",
    "    minHamPer_list.append(HamPer[1])\n",
    "    maxHamPer_list.append(HamPer[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'seqVars':seqVars_list,'max_homology':maxhomology_list,'min_homology':minhomology_list,'meanHamPer':meanHamPer_list,'minHamPer':minHamPer_list,'maxHamPer':maxHamPer_list})\n",
    "result.to_excel('result_cerevisiae_20230809.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
